{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Recognition for Diabetes Cure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential     #used to initialize the model \n",
    "from tensorflow.keras.layers import Dense          #used for adding (building) layers\n",
    "from tensorflow.keras.layers import Conv2D         #convolution layer\n",
    "from tensorflow.keras.layers import MaxPool2D      #max pooling layer\n",
    "from tensorflow.keras.layers import Flatten        #flatten layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator   #used for passing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,horizontal_flip=True,zoom_range=0.2) \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 414 images belonging to 2 classes.\n",
      "Found 153 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r'C:\\Users\\Pratiksha Bongale\\OneDrive\\Desktop\\SmartBridge\\Plant Recognition for Drug Industry\\Dataset\\train',target_size=(64,64),batch_size=32,class_mode='categorical')\n",
    "x_test = test_datagen.flow_from_directory(r'C:\\Users\\Pratiksha Bongale\\OneDrive\\Desktop\\SmartBridge\\Plant Recognition for Drug Industry\\Dataset\\test',target_size=(64,64),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,4,4,input_shape=(64,64,3),activation='relu'))\n",
    "\n",
    "#32 - number of feature detector, 4,4- size\n",
    "#input_shape - expected input shape (64,64) and 3- RGB  (1-Grey Scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "=================================================================\n",
      "Total params: 1,568\n",
      "Trainable params: 1,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=128,activation='relu',kernel_initializer='random_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=2,kernel_initializer='random_uniform',activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 264,098\n",
      "Trainable params: 264,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',loss='categorical_crossentropy',metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'can_cure': 0, 'cant_cure': 1}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)   #to check what's 0 and 1\n",
    "                               #dimention of x_train is 4== (number of images, height,width,rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "13/12 [==============================] - 4s 342ms/step - loss: 0.5169 - accuracy: 0.7729 - val_loss: 0.7041 - val_accuracy: 0.6732\n",
      "Epoch 2/70\n",
      "13/12 [==============================] - 2s 164ms/step - loss: 0.4575 - accuracy: 0.8068 - val_loss: 0.6422 - val_accuracy: 0.6732\n",
      "Epoch 3/70\n",
      "13/12 [==============================] - 2s 169ms/step - loss: 0.4238 - accuracy: 0.8068 - val_loss: 0.5322 - val_accuracy: 0.6732\n",
      "Epoch 4/70\n",
      "13/12 [==============================] - 2s 166ms/step - loss: 0.3984 - accuracy: 0.8164 - val_loss: 0.6624 - val_accuracy: 0.6732\n",
      "Epoch 5/70\n",
      "13/12 [==============================] - 2s 164ms/step - loss: 0.3964 - accuracy: 0.8188 - val_loss: 0.5081 - val_accuracy: 0.6863\n",
      "Epoch 6/70\n",
      "13/12 [==============================] - 8s 618ms/step - loss: 0.3758 - accuracy: 0.8406 - val_loss: 0.5395 - val_accuracy: 0.6928\n",
      "Epoch 7/70\n",
      "13/12 [==============================] - 3s 260ms/step - loss: 0.3641 - accuracy: 0.8406 - val_loss: 0.5392 - val_accuracy: 0.6928\n",
      "Epoch 8/70\n",
      "13/12 [==============================] - 4s 298ms/step - loss: 0.3470 - accuracy: 0.8454 - val_loss: 0.3805 - val_accuracy: 0.8301\n",
      "Epoch 9/70\n",
      "13/12 [==============================] - 4s 295ms/step - loss: 0.3318 - accuracy: 0.8454 - val_loss: 0.3864 - val_accuracy: 0.7908\n",
      "Epoch 10/70\n",
      "13/12 [==============================] - 4s 288ms/step - loss: 0.3251 - accuracy: 0.8430 - val_loss: 0.3839 - val_accuracy: 0.7974\n",
      "Epoch 11/70\n",
      "13/12 [==============================] - 4s 284ms/step - loss: 0.3143 - accuracy: 0.8478 - val_loss: 0.4237 - val_accuracy: 0.7320\n",
      "Epoch 12/70\n",
      "13/12 [==============================] - 4s 284ms/step - loss: 0.2960 - accuracy: 0.8575 - val_loss: 0.3822 - val_accuracy: 0.7974\n",
      "Epoch 13/70\n",
      "13/12 [==============================] - 4s 294ms/step - loss: 0.2816 - accuracy: 0.8865 - val_loss: 0.2884 - val_accuracy: 0.8693\n",
      "Epoch 14/70\n",
      "13/12 [==============================] - 4s 286ms/step - loss: 0.2731 - accuracy: 0.8889 - val_loss: 0.4296 - val_accuracy: 0.7516\n",
      "Epoch 15/70\n",
      "13/12 [==============================] - 4s 291ms/step - loss: 0.2450 - accuracy: 0.8913 - val_loss: 0.3628 - val_accuracy: 0.8039\n",
      "Epoch 16/70\n",
      "13/12 [==============================] - 4s 293ms/step - loss: 0.2622 - accuracy: 0.8937 - val_loss: 0.2948 - val_accuracy: 0.8627\n",
      "Epoch 17/70\n",
      "13/12 [==============================] - 4s 284ms/step - loss: 0.2278 - accuracy: 0.9155 - val_loss: 0.3676 - val_accuracy: 0.8170\n",
      "Epoch 18/70\n",
      "13/12 [==============================] - 4s 292ms/step - loss: 0.2411 - accuracy: 0.8961 - val_loss: 0.3019 - val_accuracy: 0.8562\n",
      "Epoch 19/70\n",
      "13/12 [==============================] - 4s 297ms/step - loss: 0.2035 - accuracy: 0.9203 - val_loss: 0.2835 - val_accuracy: 0.8758\n",
      "Epoch 20/70\n",
      "13/12 [==============================] - 4s 291ms/step - loss: 0.2115 - accuracy: 0.9155 - val_loss: 0.3211 - val_accuracy: 0.8693\n",
      "Epoch 21/70\n",
      "13/12 [==============================] - 4s 282ms/step - loss: 0.2012 - accuracy: 0.9155 - val_loss: 0.2734 - val_accuracy: 0.8693\n",
      "Epoch 22/70\n",
      "13/12 [==============================] - 4s 272ms/step - loss: 0.1753 - accuracy: 0.9348 - val_loss: 0.3544 - val_accuracy: 0.8627\n",
      "Epoch 23/70\n",
      "13/12 [==============================] - 3s 254ms/step - loss: 0.1809 - accuracy: 0.9251 - val_loss: 0.2480 - val_accuracy: 0.8954\n",
      "Epoch 24/70\n",
      "13/12 [==============================] - 4s 297ms/step - loss: 0.2025 - accuracy: 0.9203 - val_loss: 0.3496 - val_accuracy: 0.8627\n",
      "Epoch 25/70\n",
      "13/12 [==============================] - 4s 284ms/step - loss: 0.1621 - accuracy: 0.9420 - val_loss: 0.2899 - val_accuracy: 0.8824\n",
      "Epoch 26/70\n",
      "13/12 [==============================] - 4s 288ms/step - loss: 0.1703 - accuracy: 0.9300 - val_loss: 0.4145 - val_accuracy: 0.8562\n",
      "Epoch 27/70\n",
      "13/12 [==============================] - 4s 285ms/step - loss: 0.1693 - accuracy: 0.9324 - val_loss: 0.2538 - val_accuracy: 0.8954\n",
      "Epoch 28/70\n",
      "13/12 [==============================] - 4s 278ms/step - loss: 0.1548 - accuracy: 0.9493 - val_loss: 0.3695 - val_accuracy: 0.8693\n",
      "Epoch 29/70\n",
      "13/12 [==============================] - 4s 290ms/step - loss: 0.1373 - accuracy: 0.9420 - val_loss: 0.5267 - val_accuracy: 0.7908\n",
      "Epoch 30/70\n",
      "13/12 [==============================] - 4s 274ms/step - loss: 0.1885 - accuracy: 0.9300 - val_loss: 0.3053 - val_accuracy: 0.8889\n",
      "Epoch 31/70\n",
      "13/12 [==============================] - 3s 263ms/step - loss: 0.1918 - accuracy: 0.9130 - val_loss: 0.2799 - val_accuracy: 0.8824\n",
      "Epoch 32/70\n",
      "13/12 [==============================] - 3s 201ms/step - loss: 0.2055 - accuracy: 0.9130 - val_loss: 0.4045 - val_accuracy: 0.8301\n",
      "Epoch 33/70\n",
      "13/12 [==============================] - 2s 185ms/step - loss: 0.1844 - accuracy: 0.9227 - val_loss: 0.3506 - val_accuracy: 0.8758\n",
      "Epoch 34/70\n",
      "13/12 [==============================] - 2s 192ms/step - loss: 0.1497 - accuracy: 0.9420 - val_loss: 0.4456 - val_accuracy: 0.8366\n",
      "Epoch 35/70\n",
      "13/12 [==============================] - 3s 192ms/step - loss: 0.1428 - accuracy: 0.9396 - val_loss: 0.3427 - val_accuracy: 0.8758\n",
      "Epoch 36/70\n",
      "13/12 [==============================] - 2s 182ms/step - loss: 0.1263 - accuracy: 0.9541 - val_loss: 0.2765 - val_accuracy: 0.8758\n",
      "Epoch 37/70\n",
      "13/12 [==============================] - 2s 191ms/step - loss: 0.1193 - accuracy: 0.9541 - val_loss: 0.3835 - val_accuracy: 0.8758\n",
      "Epoch 38/70\n",
      "13/12 [==============================] - 3s 200ms/step - loss: 0.1187 - accuracy: 0.9589 - val_loss: 0.3930 - val_accuracy: 0.8758\n",
      "Epoch 39/70\n",
      "13/12 [==============================] - 3s 199ms/step - loss: 0.0976 - accuracy: 0.9662 - val_loss: 0.3746 - val_accuracy: 0.8824\n",
      "Epoch 40/70\n",
      "13/12 [==============================] - 3s 208ms/step - loss: 0.1004 - accuracy: 0.9783 - val_loss: 0.3050 - val_accuracy: 0.8954\n",
      "Epoch 41/70\n",
      "13/12 [==============================] - 2s 190ms/step - loss: 0.1206 - accuracy: 0.9589 - val_loss: 0.2712 - val_accuracy: 0.8889\n",
      "Epoch 42/70\n",
      "13/12 [==============================] - 3s 197ms/step - loss: 0.1091 - accuracy: 0.9614 - val_loss: 0.3490 - val_accuracy: 0.8889\n",
      "Epoch 43/70\n",
      "13/12 [==============================] - 3s 204ms/step - loss: 0.1009 - accuracy: 0.9565 - val_loss: 0.3609 - val_accuracy: 0.8889\n",
      "Epoch 44/70\n",
      "13/12 [==============================] - 3s 213ms/step - loss: 0.0936 - accuracy: 0.9638 - val_loss: 0.2923 - val_accuracy: 0.9150\n",
      "Epoch 45/70\n",
      "13/12 [==============================] - 3s 197ms/step - loss: 0.1444 - accuracy: 0.9541 - val_loss: 0.3377 - val_accuracy: 0.8954\n",
      "Epoch 46/70\n",
      "13/12 [==============================] - 3s 205ms/step - loss: 0.0781 - accuracy: 0.9855 - val_loss: 0.2858 - val_accuracy: 0.9020\n",
      "Epoch 47/70\n",
      "13/12 [==============================] - 3s 194ms/step - loss: 0.0744 - accuracy: 0.9807 - val_loss: 0.3541 - val_accuracy: 0.8889\n",
      "Epoch 48/70\n",
      "13/12 [==============================] - 3s 221ms/step - loss: 0.0707 - accuracy: 0.9758 - val_loss: 0.4369 - val_accuracy: 0.8693\n",
      "Epoch 49/70\n",
      "13/12 [==============================] - 3s 201ms/step - loss: 0.0678 - accuracy: 0.9831 - val_loss: 0.4136 - val_accuracy: 0.8758\n",
      "Epoch 50/70\n",
      "13/12 [==============================] - 2s 185ms/step - loss: 0.0682 - accuracy: 0.9831 - val_loss: 0.3495 - val_accuracy: 0.8954\n",
      "Epoch 51/70\n",
      "13/12 [==============================] - 3s 223ms/step - loss: 0.0790 - accuracy: 0.9758 - val_loss: 0.3051 - val_accuracy: 0.9020\n",
      "Epoch 52/70\n",
      "13/12 [==============================] - 3s 223ms/step - loss: 0.1130 - accuracy: 0.9614 - val_loss: 0.2650 - val_accuracy: 0.9020\n",
      "Epoch 53/70\n",
      "13/12 [==============================] - 3s 202ms/step - loss: 0.1133 - accuracy: 0.9638 - val_loss: 0.3565 - val_accuracy: 0.8889\n",
      "Epoch 54/70\n",
      "13/12 [==============================] - 3s 194ms/step - loss: 0.0895 - accuracy: 0.9662 - val_loss: 0.4480 - val_accuracy: 0.8693\n",
      "Epoch 55/70\n",
      "13/12 [==============================] - 2s 191ms/step - loss: 0.1010 - accuracy: 0.9493 - val_loss: 0.3667 - val_accuracy: 0.8889\n",
      "Epoch 56/70\n",
      "13/12 [==============================] - 3s 197ms/step - loss: 0.0646 - accuracy: 0.9855 - val_loss: 0.3370 - val_accuracy: 0.8954\n",
      "Epoch 57/70\n",
      "13/12 [==============================] - 3s 222ms/step - loss: 0.0660 - accuracy: 0.9734 - val_loss: 0.4374 - val_accuracy: 0.8889\n",
      "Epoch 58/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/12 [==============================] - 3s 202ms/step - loss: 0.0657 - accuracy: 0.9758 - val_loss: 0.3308 - val_accuracy: 0.9020\n",
      "Epoch 59/70\n",
      "13/12 [==============================] - 3s 199ms/step - loss: 0.0605 - accuracy: 0.9783 - val_loss: 0.4506 - val_accuracy: 0.8824\n",
      "Epoch 60/70\n",
      "13/12 [==============================] - 2s 189ms/step - loss: 0.0805 - accuracy: 0.9710 - val_loss: 0.6311 - val_accuracy: 0.8497\n",
      "Epoch 61/70\n",
      "13/12 [==============================] - 2s 185ms/step - loss: 0.0702 - accuracy: 0.9783 - val_loss: 0.4698 - val_accuracy: 0.8954\n",
      "Epoch 62/70\n",
      "13/12 [==============================] - 3s 197ms/step - loss: 0.0605 - accuracy: 0.9758 - val_loss: 0.3913 - val_accuracy: 0.8954\n",
      "Epoch 63/70\n",
      "13/12 [==============================] - 3s 201ms/step - loss: 0.0467 - accuracy: 0.9903 - val_loss: 0.3168 - val_accuracy: 0.8954\n",
      "Epoch 64/70\n",
      "13/12 [==============================] - 3s 195ms/step - loss: 0.0476 - accuracy: 0.9855 - val_loss: 0.3899 - val_accuracy: 0.8954\n",
      "Epoch 65/70\n",
      "13/12 [==============================] - 2s 183ms/step - loss: 0.0510 - accuracy: 0.9831 - val_loss: 0.3651 - val_accuracy: 0.9020\n",
      "Epoch 66/70\n",
      "13/12 [==============================] - 2s 190ms/step - loss: 0.0482 - accuracy: 0.9831 - val_loss: 0.6039 - val_accuracy: 0.8497\n",
      "Epoch 67/70\n",
      "13/12 [==============================] - 2s 190ms/step - loss: 0.0592 - accuracy: 0.9686 - val_loss: 0.4295 - val_accuracy: 0.8824\n",
      "Epoch 68/70\n",
      "13/12 [==============================] - 2s 191ms/step - loss: 0.0446 - accuracy: 0.9855 - val_loss: 0.4204 - val_accuracy: 0.9085\n",
      "Epoch 69/70\n",
      "13/12 [==============================] - 3s 198ms/step - loss: 0.0888 - accuracy: 0.9734 - val_loss: 0.2967 - val_accuracy: 0.9020\n",
      "Epoch 70/70\n",
      "13/12 [==============================] - 3s 200ms/step - loss: 0.0549 - accuracy: 0.9807 - val_loss: 0.3049 - val_accuracy: 0.8954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29fb182b250>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=414/32,validation_data=x_test,epochs=70,validation_steps=153/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('plant.h5')      #saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model  \n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('plant.h5')\n",
    "model.compile(optimizer = 'adam',loss='categorical_crossentropy',metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(frame):\n",
    "    try:\n",
    "        img = resize(frame,(64,64))\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "        if(np.max(img)>1):\n",
    "            img = img/255.0\n",
    "        prediction = model.predict(img)    \n",
    "        print(prediction)\n",
    "        prediction_class = model.predict_classes(img)\n",
    "        print(prediction_class)   #gives class name\n",
    "    except AttributeError:\n",
    "        print(\"Shape not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 1.5819296e-14]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "frame = cv2.imread(r\"C:\\Users\\Pratiksha Bongale\\OneDrive\\Desktop\\SmartBridge\\Plant Recognition for Drug Industry\\Dataset\\test\\can_cure\\l14.jpg\") #to read image\n",
    "data = detect(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00522248 0.99477756]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "frame = cv2.imread(r\"C:\\Users\\Pratiksha Bongale\\OneDrive\\Desktop\\SmartBridge\\Plant Recognition for Drug Industry\\Dataset\\test\\cant_cure\\e19.jpg\") #to read image\n",
    "data = detect(frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
